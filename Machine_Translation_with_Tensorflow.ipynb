{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Translation with Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMulilOlBiShyKQrT3bM/fz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Auckland68/NLP-Tensorflow-Projects/blob/main/Machine_Translation_with_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJzA5c3YsKqp"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow import keras "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl0cH1dbrw8h"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWRxUtBasWvg",
        "outputId": "789d8c38-4ce9-4d14-b618-c3fae90889cf"
      },
      "source": [
        "train, test = train_test_split(pd.read_csv(\"gdrive/MyDrive/ita.csv\", sep='\\\\t',header = None, nrows=100000) , test_size=.10) "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCeEcKKuumJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1dd8642-0bc5-4c73-ac80-d4576b3dc63c"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nloRdlAaumNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4369a3f1-d24a-4ec9-ceef-96f1a02cdf67"
      },
      "source": [
        "test.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWhvv3ILumRE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "f7d6b683-2d3a-46d0-e44f-5cda32e3e478"
      },
      "source": [
        "train.columns = [\"English\",\"Italian\"]\n",
        "train.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8780</th>\n",
              "      <td>It's a shame.</td>\n",
              "      <td>È un peccato.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95381</th>\n",
              "      <td>Don't eat the oysters.</td>\n",
              "      <td>Non mangiate le ostriche.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38594</th>\n",
              "      <td>They're not good.</td>\n",
              "      <td>Non sono bravi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79584</th>\n",
              "      <td>You weren't invited.</td>\n",
              "      <td>Voi non siete stati invitati.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69346</th>\n",
              "      <td>I am bored to death.</td>\n",
              "      <td>Io sono annoiato a morte.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      English                        Italian\n",
              "8780            It's a shame.                  È un peccato.\n",
              "95381  Don't eat the oysters.      Non mangiate le ostriche.\n",
              "38594       They're not good.                Non sono bravi.\n",
              "79584    You weren't invited.  Voi non siete stati invitati.\n",
              "69346    I am bored to death.      Io sono annoiato a morte."
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmdroeJOy3Kg"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gg_xnzdwSsD"
      },
      "source": [
        "train[\"lower\"] = train[\"English\"].str.lower()\n",
        "train[\"punc\"] = train[\"English\"].str.replace('[^\\w\\s]','')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37GImv-owSvy"
      },
      "source": [
        "train['lower_it'] = train[\"Italian\"].str.lower()\n",
        "train['punc_it'] =  '_start_' + ' ' +train['lower_it'].str.replace('[^\\w\\s]','')+ ' ' +'_end_'"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "M0gya7pIwSz0",
        "outputId": "0d88eb6a-7ed6-4235-fad2-1d8b8a9821b5"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Italian</th>\n",
              "      <th>lower</th>\n",
              "      <th>punc</th>\n",
              "      <th>lower_it</th>\n",
              "      <th>punc_it</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8780</th>\n",
              "      <td>It's a shame.</td>\n",
              "      <td>È un peccato.</td>\n",
              "      <td>it's a shame.</td>\n",
              "      <td>Its a shame</td>\n",
              "      <td>è un peccato.</td>\n",
              "      <td>_start_ è un peccato _end_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95381</th>\n",
              "      <td>Don't eat the oysters.</td>\n",
              "      <td>Non mangiate le ostriche.</td>\n",
              "      <td>don't eat the oysters.</td>\n",
              "      <td>Dont eat the oysters</td>\n",
              "      <td>non mangiate le ostriche.</td>\n",
              "      <td>_start_ non mangiate le ostriche _end_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38594</th>\n",
              "      <td>They're not good.</td>\n",
              "      <td>Non sono bravi.</td>\n",
              "      <td>they're not good.</td>\n",
              "      <td>Theyre not good</td>\n",
              "      <td>non sono bravi.</td>\n",
              "      <td>_start_ non sono bravi _end_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79584</th>\n",
              "      <td>You weren't invited.</td>\n",
              "      <td>Voi non siete stati invitati.</td>\n",
              "      <td>you weren't invited.</td>\n",
              "      <td>You werent invited</td>\n",
              "      <td>voi non siete stati invitati.</td>\n",
              "      <td>_start_ voi non siete stati invitati _end_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69346</th>\n",
              "      <td>I am bored to death.</td>\n",
              "      <td>Io sono annoiato a morte.</td>\n",
              "      <td>i am bored to death.</td>\n",
              "      <td>I am bored to death</td>\n",
              "      <td>io sono annoiato a morte.</td>\n",
              "      <td>_start_ io sono annoiato a morte _end_</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      English  ...                                     punc_it\n",
              "8780            It's a shame.  ...                  _start_ è un peccato _end_\n",
              "95381  Don't eat the oysters.  ...      _start_ non mangiate le ostriche _end_\n",
              "38594       They're not good.  ...                _start_ non sono bravi _end_\n",
              "79584    You weren't invited.  ...  _start_ voi non siete stati invitati _end_\n",
              "69346    I am bored to death.  ...      _start_ io sono annoiato a morte _end_\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkD5z5lQumZj"
      },
      "source": [
        "# Set parameters\n",
        "max_feat = 5000\n",
        "maxlen = 100\n",
        "\n",
        "max_feat2 = 5000\n",
        "maxlen2 = 100"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnEQNVITxI-V"
      },
      "source": [
        "# Create word embeddings for english, tokenize, create sequences and pad to 20 characters\n",
        "tok1 = keras.preprocessing.text.Tokenizer(num_words=max_feat) \n",
        "tok1.fit_on_texts(list(train['punc']))\n",
        "tf_train_english =tok1.texts_to_sequences(list(train['punc']))\n",
        "tf_train_english =keras.preprocessing.sequence.pad_sequences(tf_train_english, maxlen=maxlen) "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sSX550ExJCA"
      },
      "source": [
        "# Create word embeddings for italian. Padding after words\n",
        "tok2 = keras.preprocessing.text.Tokenizer(num_words=max_feat2, filters = '*') \n",
        "tok2.fit_on_texts(list(train['punc_it'])) \n",
        "tf_train_italian = tok2.texts_to_sequences(list(train['punc_it']))\n",
        "tf_train_italian = keras.preprocessing.sequence.pad_sequences(tf_train_italian, maxlen=maxlen2, padding ='post') "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Da6B3SKywr2"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQLzUANCxJG1",
        "outputId": "76f8f110-e441-4390-e913-f68554b531fa"
      },
      "source": [
        "# Decoder\n",
        "vectorized_italian = tf_train_italian # For Decoder Input, you don't need the last word\n",
        "decoder_input_data = vectorized_italian[:, :-1]\n",
        "decoder_target_data = vectorized_italian[:, 1:] # Decoder Target Data Is Ahead By 1 Time Step From Decoder Input Data \n",
        "\n",
        "print(f'Shape of decoder input: {decoder_input_data.shape}')\n",
        "print(f'Shape of decoder target: {decoder_target_data.shape}')\n",
        "\n",
        "# Encoder\n",
        "vectorized_english = tf_train_english \n",
        "encoder_input_data = vectorized_english\n",
        "doc_length = encoder_input_data.shape[1]\n",
        "print(f'Shape of encoder input: {encoder_input_data.shape}')\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of decoder input: (90000, 99)\n",
            "Shape of decoder target: (90000, 99)\n",
            "Shape of encoder input: (90000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi-nw1bL1w6O",
        "outputId": "8f9b1853-d9a1-4926-ad86-e6025a360e77"
      },
      "source": [
        "# Set parameters\n",
        "vocab_size_encoder = len(tok1.word_index) + 1 \n",
        "vocab_size_decoder = len(tok1.word_index) + 1\n",
        "\n",
        "print(vocab_size_encoder)\n",
        "print(vocab_size_decoder)\n",
        "\n",
        "latent_dim = 40"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6187\n",
            "6187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8szFLTxu2Uul"
      },
      "source": [
        "encoder_inputs = keras.Input(shape=(doc_length,), name='Encoder-Input')\n",
        "\n",
        "# Word embeding for encoder (English text)\n",
        "x = keras.layers.Embedding(vocab_size_encoder, latent_dim, name='Body-Word-Embedding', mask_zero=False)(encoder_inputs)\n",
        "x = tf.keras.layers.BatchNormalization(name='Encoder-Batchnorm-1')(x) # to set distribution of inputs use batch_norm\n",
        "_, state_h = tf.keras.layers.GRU(latent_dim, return_state=True, name='Encoder-Last-GRU')(x) # fixed hidden state of input\n",
        "encoder_model = keras.Model(inputs=encoder_inputs, outputs=state_h, name='Encoder-Model') \n",
        "seq2seq_encoder_out = encoder_model(encoder_inputs)\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = keras.Input(shape=(None,), name='Decoder-Input')  \n",
        "dec_emb = keras.layers.Embedding(vocab_size_decoder, latent_dim, name='Decoder-Word-Embedding', mask_zero=False)(decoder_inputs)\n",
        "dec_bn = keras.layers.BatchNormalization(name='Decoder-Batchnorm-1')(dec_emb)\n",
        "decoder_gru = keras.layers.GRU(latent_dim, return_state=True, return_sequences=True, name='Decoder-GRU')\n",
        "decoder_gru_output, _ = decoder_gru(dec_bn, initial_state=seq2seq_encoder_out) #the decoder \"decodes\" the encoder output.\n",
        "x = keras.layers.BatchNormalization(name='Decoder-Batchnorm-2')(decoder_gru_output)\n",
        "\n",
        "# Dense layer for prediction\n",
        "decoder_dense = keras.layers.Dense(vocab_size_decoder, activation='softmax', name='Final-Output-Dense')\n",
        "decoder_outputs = decoder_dense(x)\n",
        "\n",
        "# Seq2seq Model\n",
        "seq2seq_Model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "seq2seq_Model.compile(optimizer=tf.keras.optimizers.Nadam(learning_rate=0.001), loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So0sL8hQ4sp-",
        "outputId": "d6f2dc8a-1e90-41e3-f870-d933ce12d9fd"
      },
      "source": [
        "seq2seq_Model.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Decoder-Input (InputLayer)      [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Word-Embedding (Embeddi (None, None, 40)     247480      Decoder-Input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Input (InputLayer)      [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Batchnorm-1 (BatchNorma (None, None, 40)     160         Decoder-Word-Embedding[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Model (Functional)      (None, 40)           257480      Encoder-Input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-GRU (GRU)               [(None, None, 40), ( 9840        Decoder-Batchnorm-1[0][0]        \n",
            "                                                                 Encoder-Model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Batchnorm-2 (BatchNorma (None, None, 40)     160         Decoder-GRU[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Final-Output-Dense (Dense)      (None, None, 6187)   253667      Decoder-Batchnorm-2[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 768,787\n",
            "Trainable params: 768,547\n",
            "Non-trainable params: 240\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd6_exw249Ar"
      },
      "source": [
        "# Train Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTwuYztC4218",
        "outputId": "a30c66e8-f185-4253-de76-67f0266ba863"
      },
      "source": [
        "batch_size = 1200\n",
        "epochs = 5\n",
        "history = seq2seq_Model.fit([encoder_input_data, decoder_input_data], np.expand_dims(decoder_target_data, -1),\n",
        "          batch_size=batch_size,  epochs=epochs,  validation_split=0.12) "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "66/66 [==============================] - 52s 710ms/step - loss: 7.9779 - val_loss: 6.9851\n",
            "Epoch 2/5\n",
            "66/66 [==============================] - 46s 702ms/step - loss: 5.2500 - val_loss: 0.5563\n",
            "Epoch 3/5\n",
            "66/66 [==============================] - 44s 668ms/step - loss: 1.5599 - val_loss: 0.7954\n",
            "Epoch 4/5\n",
            "66/66 [==============================] - 46s 700ms/step - loss: 0.4042 - val_loss: 1.0812\n",
            "Epoch 5/5\n",
            "66/66 [==============================] - 46s 703ms/step - loss: 0.2886 - val_loss: 1.2151\n"
          ]
        }
      ]
    }
  ]
}